{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install opencv-python # Required for cv2 module to be found.",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting opencv-python\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n\u001b[K     |████████████████████████████████| 26.6MB 19kB/s  eta 0:00:01     |██████████████████████████      | 21.5MB 533kB/s eta 0:00:10\n\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from opencv-python) (1.16.2)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.1.0.25\n\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.keras import layers\nimport pickle\nimport tarfile\nimport numpy as np\nimport scipy as sc\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport math\nimport matplotlib.pyplot as plt",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "--2019-08-16 00:55:29--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\nResolving webproxy (webproxy)... 10.36.19.1\nConnecting to webproxy (webproxy)|10.36.19.1|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 170498071 (163M) [application/x-gzip]\nSaving to: ‘cifar-10-python.tar.gz’\n\ncifar-10-python.tar 100%[===================>] 162.60M  1.43MB/s    in 1m 40s  \n\n2019-08-16 00:57:10 (1.62 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Extract dataset.\ntar = tarfile.open(\"cifar-10-python.tar.gz\")\ntar.extractall()\ntar.close",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "<bound method TarFile.close of <tarfile.TarFile object at 0x7f536f29b588>>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Read in first data_batch.\nwith open(\"cifar-10-batches-py/data_batch_1\", \"rb\") as fo:\n    data_batch = pickle.load(fo, encoding=\"bytes\")",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Obtain the numpy array for the values of all the pixels in the data set and also the array of labels telling us what numpy array set is what type of picture.\nimage_height = 32\nimage_width = 32\npixels = data_batch[b\"data\"].reshape(len(data_batch[b\"labels\"]), 3, image_width, image_height)\nlabels = data_batch[b\"labels\"]",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Median filter operation to get rid of noise in the picture.\nrgb = 3\nfor i in range(len(pixels)):\n    for j in range(rgb):\n        final = sc.ndimage.filters.median_filter(pixels[i][j], size = (3, 3))\n        pixels[i][j] = final",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Adaptive histogram equalisation to sharpen contrast of the image while trying not to lose information with the blurring of lines/features\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\nfor i in range(len(pixels)):\n    for j in range(rgb):\n        final = clahe.apply(pixels[i][j])\n        pixels[i][j] = final",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Restting the tensorflow graph just in case it still is holding left over info, also reading in the test set from the dataset so we can use our trained model to predict training set pictures.\ntf.reset_default_graph()\n\nwith open(\"cifar-10-batches-py/test_batch\", \"rb\") as fo:\n    test_set = pickle.load(fo, encoding=\"bytes\")\n\ntest_pixels = data_batch[b\"data\"].reshape(len(data_batch[b\"labels\"]), 3, image_width, image_height)\ntest_labels = data_batch[b\"labels\"]\n\nx_train = pixels\ny_train = labels\nx_test = test_pixels\ny_test = test_labels",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Intensity/brightness of each pixel will range from 1-255 and this is a problem for out selu function, as the values of the pixel increase then the function output linear increases. \n# This activation weight is large will result in our model beind dependant on his weigth when looking at unseen data, this is overfitting.\nx_train = pixels.astype(\"float32\")\nx_test = x_test.astype(\"float32\")\n\nmean = np.mean(x_train)\nstd = np.std(x_train)\nx_train = (x_train - mean)/(std + 1e-7)\nx_test = (x_test - mean)/(std + 1e-7)",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Chaning our train/test labels to an adjacency matrix.\nnum_classes = 10\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Tensorflow expects to read in the training/test set in this orientation so transpose the data to make them valid inputs\nx_train = x_train.transpose(0, 2, 3, 1)\nx_test = x_test.transpose(0, 2, 3, 1)",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Calls the sequential model API which allows use to create a model and add tensor and fully connected layers one by one. Each layer creates a weght when learning and the next layer builds on the previous layers weights to better generalise the training data.\nmodel = tf.keras.models.Sequential()",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This is adding the first convolutional layer to our sequential model. \n# Convolutional layers are similar to the moving window transform used in median filtering, we take a kernal_size in this case [3, 3] and dot product with every value in the input resulting in weights, \n# we then use these weights to try find some feature unique to the input that we can learn from and generalise to other inputs that have similar features. 32 = filter size.\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", input_shape = x_train.shape[1:]))\n# Activation selu (scaled exponential linear units) is an activation function that can handle small negative values with a negative log curve (neurons can still be updated and learn). It takes in inputs and gives an output that is a generalisation of the inputs.\nmodel.add(tf.keras.layers.Activation(\"selu\"))\n# Like how we normalise our input data we also normalise the weight outputs by subtracting the mean and dividing the by the outputs standard deviation. This helps smooth out values with large weights and reduce overfitting from covariance shit.\n# If we learnt on a dataset containing a bunch of white aeroplanes then if we try to generalise to unseen aeroplanes that may be blue then our model will perform bad without batch normalisation. Batch normalisation stops the colour white from being a large influence\n# on how the model predicts an aeroplane.\nmodel.add(tf.keras.layers.BatchNormalization())\n# Max pooling downsamples the the fature map output from the convolutional layer, this is so we can make our feature map overfit less and be more robust to rotation, zoom etc. This is because we take the feature map and convert it to a \"lower resolution\" pixel map\n# where features are weighted in smaller batches to allow for movement when upscaling the array. For example if we weight a line in the image as being 2 pixels wide then max pooling may downscale this to 1 pixel wide allowing for movement and less emphasis on the need\n# for the picture to include the line. [2, 2] means we halve the image in both x and y direction (downscale by 2)\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n# Dropout randomly takes some of the output weights (trained neuron) and removes them from the training data (in this case we remove 30% at this step). This is because weights will eventually settle on simalar patterns they have been representing from images, so to\n# combat this we randomly remove some and rely on the surrounding neurons to convey the change in the local area. This helps reduce overfitting by stopping the reliance on a single feature and make generalisation more robust.\nmodel.add(tf.keras.layers.Dropout(0.4))",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Second convolutional layer.\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"))\nmodel.add(tf.keras.layers.Activation(\"selu\"))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.4))",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Third convolutional layer.\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"))\nmodel.add(tf.keras.layers.Activation(\"selu\"))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.4))",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Flatten, removes all the dimensions of our layers into a 1D array\nmodel.add(tf.keras.layers.Flatten())",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# First fully-connected layer.\n# Dense takes the 1D flattened array represents all the input neurons as 512 output neurons.\nmodel.add(tf.keras.layers.Dense(512))\nmodel.add(tf.keras.layers.Activation(\"selu\"))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.BatchNormalization())",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Second fully-connected layer.\n# This dense takes in the above layer and represents all the input neurons into 10 neurons which correspond to the final output of what image is classified as what.\nmodel.add(tf.keras.layers.Dense(num_classes))\n# Softmax outputs a value between 0 and 1 for how much each neuron represents of the whole, in this case this will represent the corresponding probability of what class(s) the given pixels/picture represents\nmodel.add(tf.keras.layers.Activation(\"softmax\"))",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 32)        896       \n_________________________________________________________________\nactivation (Activation)      (None, 32, 32, 32)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 32, 32, 32)        128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 16, 16, 64)        0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 16, 16, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 8, 8, 64)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 8, 8, 128)         0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 8, 8, 128)         512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               1049088   \n_________________________________________________________________\nactivation_3 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 10)                0         \n=================================================================\nTotal params: 1,150,410\nTrainable params: 1,148,938\nNon-trainable params: 1,472\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ADAM optimiser is similar to stochastic gradient descent but keeps both the average training step and the covariance of the training step to avoid local minima and obtain the next best weight.\n# categorical_crossentropy and accuracy are both used to return the training set loos and accuracy as well as the validation set loss and accuracy. Accuracy is a percentage of the correctly classified pictures and loss is the log sum of all the images incorrectly classified\nmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Datagen is a form of preprocessing used to change the rotation/width/height of an image so that the model can learn to be more robust and generalise for images not taken perfectly square on.\ndatagen = ImageDataGenerator(rotation_range = 5, width_shift_range = 0.08, height_shift_range = 0.08, horizontal_flip = True)\ndatagen.fit(x_train)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Batch size is how many groups the model is split up into and are run through till the model is updated.\nbatch_size = 64\n# Epochs is the number of \"full\" runs from start to finish of training.\nepochs = 150",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Reduce learning rate when the weights stop improving so we dont learn useless data\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.2, patience = 5, min_lr = 0.001)\n# Steps per epoch is the amound of steps the model has to train before the epoch has completed (being a \"full\" run through of the dataset)\ntraining = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), steps_per_epoch = x_train.shape[0] / batch_size, epochs = epochs, validation_data=(x_test, y_test), callbacks = [reduce_lr])\n# Score tells us the final validation loss and accuracy on an unseen test set that our model can predict for.\nfinal_score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 1)\n\nprint(\"Validation loss: \", final_score[0])\nprint(\"Validation accuracy: \", final_score[1])",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e2fbb7e44d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tests loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tests accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot showing the change in training loss and validation loss over time as the amount of epochs the model goes though increases.\nplt.plot(training.history[\"loss\"])\nplt.plot(training.history[\"val_loss\"])\nplt.title(\"Training loss and validation loss over time as the number of epochs increase\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Training loss\", \"Validation loss\"])\nplt.show()\n\n# Plot showing the change in accuracy of the training and accuracy of testing predictions over time as the amount of epochs the model goes though increases.\nplt.plot(model.history[\"acc\"])\nplt.plot(model.history[\"val_acc\"])\nplt.title(\"Training accuracy and validation accuracy over time as the number of epochs increase\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Training accuracy\", \"Validation accuracy\"])\nplt.show()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'training' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-db789c4bfbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training loss and validation loss over time as the number of epochs increase\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}